{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7340ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# ------------- visualizations:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "import sklearn\n",
    "from sklearn import preprocessing, metrics, pipeline, model_selection, feature_extraction \n",
    "from sklearn import naive_bayes, linear_model, svm, neural_network, neighbors, tree\n",
    "from sklearn import decomposition, cluster\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ----------------- output and visualizations: \n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c047b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# --------- Text analysis and Hebrew text analysis imports:\n",
    "# vectorizers:\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# regular expressions:\n",
    "import re\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2887f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d1b5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers_lst = [(CountVectorizer, {'min_df' : 5, 'max_df' : 1.0, 'ngram_range' : (1, 3)}),\n",
    "                   (TfidfVectorizer, {'min_df' : 5, 'max_df' : 1.0, 'ngram_range' : (1, 3)}),\n",
    "                   (CountVectorizer, {'min_df' : 0.01, 'max_df' : 0.99, 'ngram_range' : (1, 2), 'max_features' : 30000}),\n",
    "                   (TfidfVectorizer, {'min_df' : 0.01, 'max_df' : 0.99, 'ngram_range' : (1, 2), 'max_features' : 30000})]\n",
    "models = [KNeighborsClassifier(), GaussianNB(), LogisticRegression()]\n",
    "models_param_lst = [{'n_neighbors' : [3, 5, 7, 9, 11]},\n",
    "                  {},\n",
    "                  {'penalty': ['l1', 'l2'], 'C': [0.01, 0.1, 1.0, 10.0, 100.0], 'solver': ['lbfgs', 'newton-cg', 'liblinear'], 'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}], 'random_state': [41, 42]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27130e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df_train):\n",
    "    #TODO add lemmatiztion and stemming\n",
    "    \n",
    "    stories_lst = list(df_train.story)\n",
    "    \n",
    "    for i in range(len(stories_lst)):\n",
    "        story = \"\"\n",
    "        #print(f\"DEBUG preprocessing ==> before cleaning story:\\n{stories_lst[i]}\")\n",
    "        \n",
    "        for letter in stories_lst[i]:\n",
    "            if letter == ' ' or (letter >= 'א' and letter <= 'ת'):\n",
    "                story += letter\n",
    "        \n",
    "        #print(f\"DEBUG preprocessing ==> after cleaning story:\\n{story}\")\n",
    "        #print(\"----------------------------------------------------------------------\")\n",
    "        stories_lst[i] = story\n",
    "    \n",
    "    df_train.story = stories_lst\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a2cdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(vectorizer, data, res_col):\n",
    "    \n",
    "    cols = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    X_train = pd.DataFrame(data.toarray(), columns=cols)\n",
    "\n",
    "    y_male = np.where(res_col == 'm', 1, 0)\n",
    "    y_female = np.where(res_col == 'f', 1, 0)\n",
    "    \n",
    "    \n",
    "    #print(f\"DEBUG vectorization ==> X_train:\\n{X_train}\")\n",
    "    #print(\"----------------------------------------------------------------------\")\n",
    "    return X_train, y_male, y_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e56bc004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(model_name, best_parameters, X_train, y_train):\n",
    "    \n",
    "    model = model_name\n",
    "    model.set_params(**best_parameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    score = cross_val_score(model, X=X_train, y=y_train, scoring='f1', cv=10).mean()\n",
    "    \n",
    "    #print(f\"DEBUG get_f1_score ==> model_name: {model}\")\n",
    "    #print(f\"DEBUG get_f1_score ==> best_params: {best_parameters}\")\n",
    "    #print(f\"DEBUG get_f1_score ==> score: {score}\")\n",
    "    \n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b686e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df(vectorizer, model, model_params, df_test, X_train, y_train, gender):\n",
    "    df = preprocessing(df_test)\n",
    "    \n",
    "    vec = vectorizer.transform(df_test[\"story\"])\n",
    "    \n",
    "    X_test = pd.DataFrame(vec.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    \n",
    "    model.set_params(**model_params)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if gender == 'm':\n",
    "        prediction_list = np.where(y_pred == 1, 'm', 'f')\n",
    "    \n",
    "    else:\n",
    "        prediction_list = np.where(y_pred == 0, 'm', 'f')\n",
    "    \n",
    "    res_df = df_test.copy()\n",
    "    res_df[\"gender\"] = prediction_list\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4c5cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'annotated_corpus_for_train.csv'\n",
    "test_filename  = 'corpus_for_test.csv'\n",
    "df_train = pd.read_csv(train_filename, index_col=None, encoding='utf-8')\n",
    "df_test  = pd.read_csv(test_filename, index_col=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "389146eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG main ==> start <class 'sklearn.feature_extraction.text.CountVectorizer'> vectorizer\n",
      "DEBUG main ==> model: KNeighborsClassifier(n_neighbors=3)\n",
      "DEBUG main ==> model: GaussianNB()\n",
      "DEBUG main ==> model: LogisticRegression(C=0.01, class_weight={0: 1, 1: 5}, random_state=41)\n",
      "---------------------------------------Good model found------------------------------------------\n",
      "DEBUG main ==> model_chose: LogisticRegression(C=0.01, class_weight={0: 1, 1: 5}, random_state=41)\n",
      "DEBUG main ==> best_male_parameters: {'C': 100.0, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'random_state': 41, 'solver': 'newton-cg'}\n",
      "DEBUG main ==> best_female_parameters: {'C': 0.01, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'random_state': 41, 'solver': 'lbfgs'}\n",
      "DEBUG main ==> male_score: 0.8816719975399602\n",
      "DEBUG main ==> female_score: 0.5638827893741348\n",
      "DEBUG main ==> avg_score: 0.7227773934570475\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> start <class 'sklearn.feature_extraction.text.TfidfVectorizer'> vectorizer\n",
      "DEBUG main ==> model: KNeighborsClassifier(n_neighbors=3)\n",
      "---------------------------------------Good model found------------------------------------------\n",
      "DEBUG main ==> model_chose: KNeighborsClassifier(n_neighbors=3)\n",
      "DEBUG main ==> best_male_parameters: {'n_neighbors': 11}\n",
      "DEBUG main ==> best_female_parameters: {'n_neighbors': 3}\n",
      "DEBUG main ==> male_score: 0.8648512472200517\n",
      "DEBUG main ==> female_score: 0.39885146568716545\n",
      "DEBUG main ==> avg_score: 0.6318513564536086\n",
      "DEBUG main ==> model: GaussianNB()\n",
      "DEBUG main ==> model: LogisticRegression(C=100.0, class_weight={0: 1, 1: 5}, random_state=41,\n",
      "                   solver='newton-cg')\n",
      "---------------------------------------Good model found------------------------------------------\n",
      "DEBUG main ==> model_chose: LogisticRegression(class_weight={0: 1, 1: 5}, random_state=41)\n",
      "DEBUG main ==> best_male_parameters: {'C': 100.0, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'random_state': 41, 'solver': 'lbfgs'}\n",
      "DEBUG main ==> best_female_parameters: {'C': 1.0, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'random_state': 41, 'solver': 'lbfgs'}\n",
      "DEBUG main ==> male_score: 0.8875642653660718\n",
      "DEBUG main ==> female_score: 0.5809867719736751\n",
      "DEBUG main ==> avg_score: 0.7342755186698735\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> start <class 'sklearn.feature_extraction.text.CountVectorizer'> vectorizer\n",
      "DEBUG main ==> model: KNeighborsClassifier(n_neighbors=11)\n",
      "DEBUG main ==> model: GaussianNB()\n",
      "DEBUG main ==> model: LogisticRegression(C=100.0, class_weight={0: 1, 1: 1}, random_state=41)\n",
      "---------------------------------------Good model found------------------------------------------\n",
      "DEBUG main ==> model_chose: LogisticRegression(C=0.01, class_weight={0: 1, 1: 3}, random_state=41,\n",
      "                   solver='liblinear')\n",
      "DEBUG main ==> best_male_parameters: {'C': 10.0, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'random_state': 41, 'solver': 'newton-cg'}\n",
      "DEBUG main ==> best_female_parameters: {'C': 0.01, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'random_state': 41, 'solver': 'liblinear'}\n",
      "DEBUG main ==> male_score: 0.8789590649737619\n",
      "DEBUG main ==> female_score: 0.5552161216386937\n",
      "DEBUG main ==> avg_score: 0.7170875933062277\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> start <class 'sklearn.feature_extraction.text.TfidfVectorizer'> vectorizer\n",
      "DEBUG main ==> model: KNeighborsClassifier(n_neighbors=3)\n",
      "---------------------------------------Good model found------------------------------------------\n",
      "DEBUG main ==> model_chose: KNeighborsClassifier(n_neighbors=3)\n",
      "DEBUG main ==> best_male_parameters: {'n_neighbors': 11}\n",
      "DEBUG main ==> best_female_parameters: {'n_neighbors': 3}\n",
      "DEBUG main ==> male_score: 0.8628134689007906\n",
      "DEBUG main ==> female_score: 0.3891519542131333\n",
      "DEBUG main ==> avg_score: 0.625982711556962\n",
      "DEBUG main ==> model: GaussianNB()\n",
      "DEBUG main ==> model: LogisticRegression(C=10.0, class_weight={0: 1, 1: 3}, random_state=41,\n",
      "                   solver='newton-cg')\n",
      "---------------------------------------Good model found------------------------------------------\n",
      "DEBUG main ==> model_chose: LogisticRegression(class_weight={0: 1, 1: 5}, random_state=41,\n",
      "                   solver='liblinear')\n",
      "DEBUG main ==> best_male_parameters: {'C': 100.0, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'random_state': 41, 'solver': 'lbfgs'}\n",
      "DEBUG main ==> best_female_parameters: {'C': 1.0, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'random_state': 41, 'solver': 'liblinear'}\n",
      "DEBUG main ==> male_score: 0.8894728432904733\n",
      "DEBUG main ==> female_score: 0.5771965824904864\n",
      "DEBUG main ==> avg_score: 0.7333347128904799\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    }
   ],
   "source": [
    "best_models = []\n",
    "\n",
    "for vectorizer_cls, v_params in vectorizers_lst:\n",
    "    print(f\"DEBUG main ==> start {str(vectorizer_cls)} vectorizer\")\n",
    "    \n",
    "    for model_i in range(len(models)):\n",
    "        print(f\"DEBUG main ==> model: {models[model_i]}\")\n",
    "        \n",
    "        df_train = preprocessing(df_train)\n",
    "        \n",
    "        vectorizer = vectorizer_cls(**v_params)\n",
    "        vectorized_data = vectorizer.fit_transform(df_train.story)\n",
    "        \n",
    "        X, y_male, y_female = vectorization(vectorizer, vectorized_data, df_train.gender)\n",
    "        \n",
    "        grid_search_model = GridSearchCV(models[model_i], models_param_lst[model_i], cv=10, scoring='f1')\n",
    "        grid_search_res_male = grid_search_model.fit(X.copy(), y_male)\n",
    "        \n",
    "        grid_search_model = GridSearchCV(models[model_i], models_param_lst[model_i], cv=10, scoring='f1')\n",
    "        grid_search_res_female = grid_search_model.fit(X.copy(), y_female)\n",
    "        \n",
    "        f1_male_score, male_trained_model = get_f1_score(models[model_i], grid_search_res_male.best_params_, X, y_male)\n",
    "        f1_female_score, female_trained_model = get_f1_score(models[model_i], grid_search_res_female.best_params_, X, y_female)\n",
    "        \n",
    "        f1_avg_score = (f1_male_score + f1_female_score)/2\n",
    "        \n",
    "        if f1_avg_score > 0.60:\n",
    "            print(\"---------------------------------------Good model found------------------------------------------\")\n",
    "            print(f\"DEBUG main ==> model_chose: {models[model_i]}\")\n",
    "            print(f\"DEBUG main ==> best_male_parameters: {grid_search_res_male.best_params_}\")\n",
    "            print(f\"DEBUG main ==> best_female_parameters: {grid_search_res_female.best_params_}\")\n",
    "            print(f\"DEBUG main ==> male_score: {f1_male_score}\")\n",
    "            print(f\"DEBUG main ==> female_score: {f1_female_score}\")\n",
    "            print(f\"DEBUG main ==> avg_score: {f1_avg_score}\")\n",
    "            \n",
    "            df_male = predict_df(vectorizer, male_trained_model, grid_search_res_male.best_params_, df_test, X, y_male, 'm')\n",
    "            df_female = predict_df(vectorizer, female_trained_model, grid_search_res_male.best_params_, df_test, X, y_female, 'f')\n",
    "            \n",
    "            best_models.append({\"f1_avg\":f1_avg_score, \"female_pred\":df_female.gender, \"man_pred\":df_male.gender})\n",
    "        \n",
    "    print(\"::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7719c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in best\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
