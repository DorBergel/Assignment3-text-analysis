{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e8abc61-e174-4439-b48f-74de946e9ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[K\n",
      "Download (0 bytes) Requesting\n",
      "\u001b[K\n",
      "Download [                              ] (0/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [=                             ] (8192/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#-                            ] (16384/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [##-                           ] (24576/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [###                           ] (32768/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [###=                          ] (40960/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [####=                         ] (49152/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#####-                        ] (57344/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [######                        ] (65536/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#######                       ] (73728/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#######=                      ] (81920/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [########-                     ] (90112/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#########-                    ] (98304/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [##########                    ] (106496/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [##########=                   ] (114688/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [###########=                  ] (122880/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [############-                 ] (131072/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#############                 ] (139264/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [##############                ] (147456/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [##############=               ] (155648/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [###############-              ] (163840/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [################-             ] (172032/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#################             ] (180224/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#################=            ] (188416/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [##################=           ] (196608/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [###################-          ] (204800/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [####################          ] (212992/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#####################         ] (221184/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#####################=        ] (229376/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [######################-       ] (237568/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#######################-      ] (245760/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [########################      ] (253952/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [########################=     ] (262144/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#########################=    ] (270336/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [##########################-   ] (278528/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [###########################   ] (286720/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [############################  ] (294912/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [############################= ] (303104/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [#############################-] (311296/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [##############################] (315276/315276 bytes) Receiving\n",
      "\u001b[K\n",
      "Download [##############################] (315276/315276 bytes) Complete\n",
      "\n",
      "\u001b[KChecking C:\\Users\\DBergel\\AppData\\Local\\Temp\\tmpixcfosow\\omw-he\\omw-he.xml\n",
      "\u001b[KReading C:\\Users\\DBergel\\AppData\\Local\\Temp\\tmpixcfosow\\omw-he\\omw-he.xml\n",
      "\u001b[K\n",
      "Read [##########                    ] (10000/29690) \n",
      "\u001b[K\n",
      "Read [####################          ] (20000/29690) \n",
      "\u001b[K\n",
      "Read [##############################] (29690/29690) \n",
      "\n",
      "\u001b[KUpdating lookup tables\n",
      "\u001b[K\n",
      "Database [                              ] (0/29687) \n",
      "\u001b[K\n",
      "Database [                              ] (0/29687) Lexicon Info\n",
      "\u001b[K\n",
      "Database [                              ] (0/29687) Synsets\n",
      "\u001b[K\n",
      "Database [#                             ] (1000/29687) Synsets\n",
      "\u001b[K\n",
      "Database [##                            ] (2000/29687) Synsets\n",
      "\u001b[K\n",
      "Database [###                           ] (3000/29687) Synsets\n",
      "\u001b[K\n",
      "Database [####                          ] (4000/29687) Synsets\n",
      "\u001b[K\n",
      "Database [#####                         ] (5000/29687) Synsets\n",
      "\u001b[K\n",
      "Database [#####-                        ] (5448/29687) Synsets\n",
      "\u001b[K\n",
      "Database [#####-                        ] (5448/29687) Words\n",
      "\u001b[K\n",
      "Database [######-                       ] (6448/29687) Words\n",
      "\u001b[K\n",
      "Database [#######-                      ] (7448/29687) Words\n",
      "\u001b[K\n",
      "Database [########-                     ] (8448/29687) Words\n",
      "\u001b[K\n",
      "Database [#########-                    ] (9448/29687) Words\n",
      "\u001b[K\n",
      "Database [##########-                   ] (10448/29687) Words\n",
      "\u001b[K\n",
      "Database [##########=                   ] (10827/29687) Words\n",
      "\u001b[K\n",
      "Database [##########=                   ] (10827/29687) Word Forms\n",
      "\u001b[K\n",
      "Database [###########=                  ] (11827/29687) Word Forms\n",
      "\u001b[K\n",
      "Database [############=                 ] (12827/29687) Word Forms\n",
      "\u001b[K\n",
      "Database [#############=                ] (13827/29687) Word Forms\n",
      "\u001b[K\n",
      "Database [##############=               ] (14827/29687) Word Forms\n",
      "\u001b[K\n",
      "Database [###############=              ] (15827/29687) Word Forms\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Word Forms\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Pronunciations\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Pronunciations\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Pronunciations\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Pronunciations\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Pronunciations\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Pronunciations\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Pronunciations\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Word Form Tags\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Word Form Tags\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Word Form Tags\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Word Form Tags\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Word Form Tags\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Word Form Tags\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Word Form Tags\n",
      "\u001b[K\n",
      "Database [################-             ] (16206/29687) Senses\n",
      "\u001b[K\n",
      "Database [##################            ] (17901/29687) Senses\n",
      "\u001b[K\n",
      "Database [###################-          ] (19154/29687) Senses\n",
      "\u001b[K\n",
      "Database [####################-         ] (20319/29687) Senses\n",
      "\u001b[K\n",
      "Database [#####################=        ] (21531/29687) Senses\n",
      "\u001b[K\n",
      "Database [######################=       ] (22671/29687) Senses\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Senses\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Sense Adjpositions\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Counts\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Counts\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Syntactic Behaviours\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Syntactic Behaviours\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Synset Relations\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Synset Relations\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Synset Relations\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Synset Relations\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Synset Relations\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Synset Relations\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Synset Relations\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Sense Relations\n",
      "\u001b[K\n",
      "Database [#######################       ] (23078/29687) Definitions\n",
      "\u001b[K\n",
      "Database [########################=     ] (24503/29687) Definitions\n",
      "\u001b[K\n",
      "Database [##########################    ] (25778/29687) Definitions\n",
      "\u001b[K\n",
      "Database [###########################   ] (27015/29687) Definitions\n",
      "\u001b[K\n",
      "Database [############################- ] (28283/29687) Definitions\n",
      "\u001b[K\n",
      "Database [#############################-] (29140/29687) Definitions\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Definitions\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) Examples\n",
      "\u001b[K\n",
      "Database [##############################] (29687/29687) \n",
      "\u001b[KAdded omw-he:1.4 (Hebrew Wordnet)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m wn download omw-he:1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f7340ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# ------------- visualizations:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "import sklearn\n",
    "from sklearn import preprocessing, metrics, pipeline, model_selection, feature_extraction \n",
    "from sklearn import naive_bayes, linear_model, svm, neural_network, neighbors, tree\n",
    "from sklearn import decomposition, cluster\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ----------------- output and visualizations: \n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c047b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# --------- Text analysis and Hebrew text analysis imports:\n",
    "# vectorizers:\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# regular expressions:\n",
    "import re\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2887f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d1b5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers_lst = [(CountVectorizer, {'min_df' : 5, 'max_df' : 1.0, 'ngram_range' : (1, 3)}),\n",
    "                   (TfidfVectorizer, {'min_df' : 5, 'max_df' : 1.0, 'ngram_range' : (1, 3)}),\n",
    "                   (CountVectorizer, {'min_df' : 0.01, 'max_df' : 0.99, 'ngram_range' : (1, 2), 'max_features' : 30000}),\n",
    "                   (TfidfVectorizer, {'min_df' : 0.01, 'max_df' : 0.99, 'ngram_range' : (1, 2), 'max_features' : 30000})]\n",
    "models = [KNeighborsClassifier(), GaussianNB(), LogisticRegression()]\n",
    "models_param_lst = [{'n_neighbors' : [3, 5, 7, 9, 11]},\n",
    "                  {},\n",
    "                  {'penalty': ['l1', 'l2'], 'C': [0.01, 0.1, 1.0, 10.0, 100.0], 'solver': ['lbfgs', 'newton-cg', 'liblinear'], 'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 3}, {0: 1, 1: 5}], 'random_state': [41, 42]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27130e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df_train):\n",
    "    #TODO add lemmatiztion and stemming\n",
    "    \n",
    "    stories_lst = list(df_train.story)\n",
    "    \n",
    "    for i in range(len(stories_lst)):\n",
    "        story = \"\"\n",
    "        #print(f\"DEBUG preprocessing ==> before cleaning story:\\n{stories_lst[i]}\")\n",
    "        \n",
    "        for letter in stories_lst[i]:\n",
    "            if letter == ' ' or (letter >= 'א' and letter <= 'ת'):\n",
    "                story += letter\n",
    "        \n",
    "        #print(f\"DEBUG preprocessing ==> after cleaning story:\\n{story}\")\n",
    "        #print(\"----------------------------------------------------------------------\")\n",
    "        stories_lst[i] = story\n",
    "    \n",
    "    df_train.story = stories_lst\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a2cdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(vectorizer, data, res_col):\n",
    "    \n",
    "    cols = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    X_train = pd.DataFrame(data.toarray(), columns=cols)\n",
    "\n",
    "    y_male = np.where(res_col == 'm', 1, 0)\n",
    "    y_female = np.where(res_col == 'f', 1, 0)\n",
    "    \n",
    "    \n",
    "    #print(f\"DEBUG vectorization ==> X_train:\\n{X_train}\")\n",
    "    #print(\"----------------------------------------------------------------------\")\n",
    "    return X_train, y_male, y_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e56bc004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(model_name, best_parameters, X_train, y_train):\n",
    "    \n",
    "    model = model_name\n",
    "    model.set_params(**best_parameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    score = cross_val_score(model, X=X_train, y=y_train, scoring='f1', cv=10).mean()\n",
    "    \n",
    "    #print(f\"DEBUG get_f1_score ==> model_name: {model}\")\n",
    "    #print(f\"DEBUG get_f1_score ==> best_params: {best_parameters}\")\n",
    "    #print(f\"DEBUG get_f1_score ==> score: {score}\")\n",
    "    \n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b686e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df(vectorizer, model, model_params, df_test, gender):\n",
    "    df = preprocessing(df_test)\n",
    "    \n",
    "    vec = vectorizer.transform(df_test[\"story\"])\n",
    "    \n",
    "    X_test = pd.DataFrame(vec.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if gender == 'm':\n",
    "        prediction_list = np.where(y_pred == 1, 'm', 'f')\n",
    "    \n",
    "    else:\n",
    "        prediction_list = np.where(y_pred == 0, 'm', 'f')\n",
    "    \n",
    "    res_df = df_test.copy()\n",
    "    res_df[\"gender\"] = prediction_list\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4c5cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'annotated_corpus_for_train.csv'\n",
    "test_filename  = 'corpus_for_test.csv'\n",
    "df_train = pd.read_csv(train_filename, index_col=None, encoding='utf-8')\n",
    "df_test  = pd.read_csv(test_filename, index_col=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "389146eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG main ==> start <class 'sklearn.feature_extraction.text.CountVectorizer'> vectorizer\n",
      "DEBUG main ==> model: KNeighborsClassifier(n_neighbors=3)\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> model: GaussianNB()\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> model: LogisticRegression(C=100.0, class_weight={0: 1, 1: 1}, random_state=41)\n",
      "---------------------------------------Good model found------------------------------------------\n",
      "DEBUG main ==> model_chose: LogisticRegression(C=0.01, class_weight={0: 1, 1: 5}, random_state=41)\n",
      "DEBUG main ==> best_male_parameters: {'C': 100.0, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'random_state': 41, 'solver': 'newton-cg'}\n",
      "DEBUG main ==> best_female_parameters: {'C': 0.01, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'random_state': 41, 'solver': 'lbfgs'}\n",
      "DEBUG main ==> male_score: 0.8816719975399602\n",
      "DEBUG main ==> female_score: 0.5638827893741348\n",
      "DEBUG main ==> avg_score: 0.7227773934570475\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> start <class 'sklearn.feature_extraction.text.TfidfVectorizer'> vectorizer\n",
      "DEBUG main ==> model: KNeighborsClassifier(n_neighbors=3)\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> model: GaussianNB()\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> model: LogisticRegression(C=0.01, class_weight={0: 1, 1: 5}, random_state=41)\n",
      "---------------------------------------Good model found------------------------------------------\n",
      "DEBUG main ==> model_chose: LogisticRegression(class_weight={0: 1, 1: 5}, random_state=41)\n",
      "DEBUG main ==> best_male_parameters: {'C': 100.0, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'random_state': 41, 'solver': 'lbfgs'}\n",
      "DEBUG main ==> best_female_parameters: {'C': 1.0, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'random_state': 41, 'solver': 'lbfgs'}\n",
      "DEBUG main ==> male_score: 0.8875642653660718\n",
      "DEBUG main ==> female_score: 0.5809867719736751\n",
      "DEBUG main ==> avg_score: 0.7342755186698735\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> start <class 'sklearn.feature_extraction.text.CountVectorizer'> vectorizer\n",
      "DEBUG main ==> model: KNeighborsClassifier(n_neighbors=3)\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> model: GaussianNB()\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> model: LogisticRegression(class_weight={0: 1, 1: 5}, random_state=41)\n",
      "---------------------------------------Good model found------------------------------------------\n",
      "DEBUG main ==> model_chose: LogisticRegression(C=0.01, class_weight={0: 1, 1: 3}, random_state=41,\n",
      "                   solver='liblinear')\n",
      "DEBUG main ==> best_male_parameters: {'C': 10.0, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'random_state': 41, 'solver': 'newton-cg'}\n",
      "DEBUG main ==> best_female_parameters: {'C': 0.01, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'random_state': 41, 'solver': 'liblinear'}\n",
      "DEBUG main ==> male_score: 0.8789590649737619\n",
      "DEBUG main ==> female_score: 0.5552161216386937\n",
      "DEBUG main ==> avg_score: 0.7170875933062277\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> start <class 'sklearn.feature_extraction.text.TfidfVectorizer'> vectorizer\n",
      "DEBUG main ==> model: KNeighborsClassifier(n_neighbors=3)\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> model: GaussianNB()\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "DEBUG main ==> model: LogisticRegression(C=0.01, class_weight={0: 1, 1: 3}, random_state=41,\n",
      "                   solver='liblinear')\n",
      "---------------------------------------Good model found------------------------------------------\n",
      "DEBUG main ==> model_chose: LogisticRegression(class_weight={0: 1, 1: 5}, random_state=41,\n",
      "                   solver='liblinear')\n",
      "DEBUG main ==> best_male_parameters: {'C': 100.0, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'random_state': 41, 'solver': 'lbfgs'}\n",
      "DEBUG main ==> best_female_parameters: {'C': 1.0, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'random_state': 41, 'solver': 'liblinear'}\n",
      "DEBUG main ==> male_score: 0.8894728432904733\n",
      "DEBUG main ==> female_score: 0.5771965824904864\n",
      "DEBUG main ==> avg_score: 0.7333347128904799\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    }
   ],
   "source": [
    "all_models_combinations = []\n",
    "\n",
    "for vectorizer_cls, v_params in vectorizers_lst:\n",
    "    print(f\"DEBUG main ==> start {str(vectorizer_cls)} vectorizer\")\n",
    "    \n",
    "    for model_i in range(len(models)):\n",
    "        print(f\"DEBUG main ==> model: {models[model_i]}\")\n",
    "        \n",
    "        df_train = preprocessing(df_train)\n",
    "        \n",
    "        vectorizer = vectorizer_cls(**v_params)\n",
    "        vectorized_data = vectorizer.fit_transform(df_train.story)\n",
    "        \n",
    "        X, y_male, y_female = vectorization(vectorizer, vectorized_data, df_train.gender)\n",
    "        \n",
    "        grid_search_model = GridSearchCV(models[model_i], models_param_lst[model_i], cv=10, scoring='f1')\n",
    "        grid_search_res_male = grid_search_model.fit(X.copy(), y_male)\n",
    "        \n",
    "        grid_search_model = GridSearchCV(models[model_i], models_param_lst[model_i], cv=10, scoring='f1')\n",
    "        grid_search_res_female = grid_search_model.fit(X.copy(), y_female)\n",
    "        \n",
    "        f1_male_score, male_trained_model = get_f1_score(models[model_i], grid_search_res_male.best_params_, X, y_male)\n",
    "        f1_female_score, female_trained_model = get_f1_score(models[model_i], grid_search_res_female.best_params_, X, y_female)\n",
    "        \n",
    "        f1_avg_score = (f1_male_score + f1_female_score)/2\n",
    "        \n",
    "        if f1_avg_score > 0.60:\n",
    "            print(\"---------------------------------------Good model found------------------------------------------\")\n",
    "            print(f\"DEBUG main ==> model_chose: {models[model_i]}\")\n",
    "            print(f\"DEBUG main ==> best_male_parameters: {grid_search_res_male.best_params_}\")\n",
    "            print(f\"DEBUG main ==> best_female_parameters: {grid_search_res_female.best_params_}\")\n",
    "            print(f\"DEBUG main ==> male_score: {f1_male_score}\")\n",
    "            print(f\"DEBUG main ==> female_score: {f1_female_score}\")\n",
    "            print(f\"DEBUG main ==> avg_score: {f1_avg_score}\")\n",
    "            \n",
    "            df_male = predict_df(vectorizer, male_trained_model, grid_search_res_male.best_params_, df_test, 'm')\n",
    "            df_female = predict_df(vectorizer, female_trained_model, grid_search_res_male.best_params_, df_test, 'f')\n",
    "            \n",
    "        all_models_combinations.append({\"f1_avg\":f1_avg_score, \"female_pred\":df_female.gender, \"man_pred\":df_male.gender, \"trained_male\":male_trained_model,\n",
    "                               \"trained_female\":female_trained_model, \"best_male_params\":grid_search_res_male.best_params_,\n",
    "                               \"best_female_params\":grid_search_res_female.best_params_, \"vectorizer\":vectorizer_cls, \"vectorizer_params\": v_params})\n",
    "        \n",
    "        print(\"::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7719c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7342755186698735\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "\n",
    "for model in all_models_combinations:\n",
    "    if model[\"f1_avg\"] > max_score:\n",
    "        max_score = model[\"f1_avg\"]\n",
    "\n",
    "print(max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709f1b4-476b-4bf1-b413-51d2f6791256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
